"""
Script d'entra√Ænement du mod√®le ML SafeQore
G√©n√®re des donn√©es synth√©tiques et entra√Æne le classifieur de risques
"""

import os
import sys
import json
import random
import joblib
import numpy as np
import pandas as pd
from datetime import datetime
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.metrics import classification_report, confusion_matrix
import warnings
warnings.filterwarnings('ignore')

# Ajouter le chemin parent pour importer les constantes
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from app.constants import RISK_CATEGORIES, RISK_TYPES, KINNEY_SCALE, SECTORS

# Configuration
OUTPUT_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
DATA_DIR = os.path.join(os.path.dirname(os.path.abspath(__file__)), 'data')


def classify_from_score(score: int) -> str:
    """Classification selon la m√©thode KINNEY - STB_AR_0006"""
    if score <= 25:
        return "Faible"
    elif score <= 50:
        return "Moyen"
    return "Eleve"


def generate_synthetic_training_data(n_samples: int = 5000) -> pd.DataFrame:
    """
    G√©n√®re des donn√©es d'entra√Ænement synth√©tiques bas√©es sur les sp√©cifications STB.

    Les donn√©es sont g√©n√©r√©es avec des distributions r√©alistes pour chaque
    combinaison cat√©gorie/type de risque.
    """
    data = []

    # Profils de risque par type (probabilit√©s de G, F, P √©lev√©s)
    risk_profiles = {
        "Commercial": {"G_bias": 0.4, "F_bias": 0.5, "P_bias": 0.4},
        "Financier": {"G_bias": 0.6, "F_bias": 0.3, "P_bias": 0.5},
        "Technique": {"G_bias": 0.5, "F_bias": 0.6, "P_bias": 0.4},
        "Cyber & SSI": {"G_bias": 0.7, "F_bias": 0.5, "P_bias": 0.6}
    }

    # Modificateurs par cat√©gorie
    category_modifiers = {
        "Projet/Programme": {"G_mod": 0.0, "F_mod": 0.1, "P_mod": 0.0},
        "Industriel": {"G_mod": 0.2, "F_mod": 0.1, "P_mod": 0.1},
        "Qualit√©": {"G_mod": -0.1, "F_mod": 0.2, "P_mod": 0.0}
    }

    for _ in range(n_samples):
        category = random.choice(RISK_CATEGORIES)
        risk_type = random.choice(RISK_TYPES)
        sector = random.choice(SECTORS)

        # Obtenir le profil de risque
        profile = risk_profiles[risk_type]
        cat_mod = category_modifiers[category]

        # Calculer les probabilit√©s ajust√©es
        g_prob = min(max(profile["G_bias"] + cat_mod["G_mod"], 0.1), 0.9)
        f_prob = min(max(profile["F_bias"] + cat_mod["F_mod"], 0.1), 0.9)
        p_prob = min(max(profile["P_bias"] + cat_mod["P_mod"], 0.1), 0.9)

        # G√©n√©rer G, F, P avec distribution pond√©r√©e (1-5)
        G = generate_weighted_value(g_prob)
        F = generate_weighted_value(f_prob)
        P = generate_weighted_value(p_prob)

        # Calculer le score et la classification
        score = G * F * P
        classification = classify_from_score(score)

        data.append({
            "G": G,
            "F": F,
            "P": P,
            "category": category,
            "type": risk_type,
            "sector": sector,
            "score": score,
            "classification": classification
        })

    return pd.DataFrame(data)


def generate_weighted_value(high_prob: float) -> int:
    """
    G√©n√®re une valeur entre 1 et 5 avec une probabilit√© pond√©r√©e.
    high_prob : probabilit√© d'obtenir des valeurs √©lev√©es (4-5)
    """
    if random.random() < high_prob:
        return random.choices([4, 5], weights=[0.6, 0.4])[0]
    else:
        return random.choices([1, 2, 3], weights=[0.3, 0.4, 0.3])[0]


def generate_realistic_scenarios() -> pd.DataFrame:
    """
    G√©n√®re des sc√©narios r√©alistes bas√©s sur des cas d'usage typiques.
    Ces donn√©es enrichissent le mod√®le avec des patterns m√©tier r√©els.
    """
    scenarios = []

    # Sc√©narios Commercial
    commercial_scenarios = [
        {"G": 3, "F": 4, "P": 3, "category": "Projet/Programme", "type": "Commercial",
         "desc": "Perte d'un client majeur"},
        {"G": 4, "F": 3, "P": 4, "category": "Projet/Programme", "type": "Commercial",
         "desc": "√âchec de n√©gociation contractuelle"},
        {"G": 2, "F": 5, "P": 2, "category": "Qualit√©", "type": "Commercial",
         "desc": "R√©clamations clients r√©currentes"},
        {"G": 5, "F": 2, "P": 3, "category": "Industriel", "type": "Commercial",
         "desc": "Rupture de partenariat strat√©gique"},
    ]

    # Sc√©narios Financier
    financial_scenarios = [
        {"G": 5, "F": 2, "P": 4, "category": "Projet/Programme", "type": "Financier",
         "desc": "D√©passement budg√©taire majeur"},
        {"G": 4, "F": 4, "P": 3, "category": "Industriel", "type": "Financier",
         "desc": "Fluctuation des co√ªts mati√®res premi√®res"},
        {"G": 3, "F": 3, "P": 4, "category": "Qualit√©", "type": "Financier",
         "desc": "P√©nalit√©s de retard"},
        {"G": 5, "F": 1, "P": 5, "category": "Projet/Programme", "type": "Financier",
         "desc": "Faillite d'un fournisseur cl√©"},
    ]

    # Sc√©narios Technique
    technical_scenarios = [
        {"G": 4, "F": 4, "P": 3, "category": "Industriel", "type": "Technique",
         "desc": "Panne √©quipement critique"},
        {"G": 3, "F": 5, "P": 4, "category": "Qualit√©", "type": "Technique",
         "desc": "Non-conformit√© produit"},
        {"G": 5, "F": 3, "P": 4, "category": "Projet/Programme", "type": "Technique",
         "desc": "Obsolescence technologique"},
        {"G": 4, "F": 3, "P": 3, "category": "Industriel", "type": "Technique",
         "desc": "D√©faillance syst√®me de production"},
    ]

    # Sc√©narios Cyber & SSI
    cyber_scenarios = [
        {"G": 5, "F": 4, "P": 4, "category": "Projet/Programme", "type": "Cyber & SSI",
         "desc": "Attaque ransomware"},
        {"G": 5, "F": 3, "P": 5, "category": "Industriel", "type": "Cyber & SSI",
         "desc": "Fuite de donn√©es sensibles"},
        {"G": 4, "F": 5, "P": 3, "category": "Qualit√©", "type": "Cyber & SSI",
         "desc": "Phishing cibl√©"},
        {"G": 5, "F": 2, "P": 4, "category": "Industriel", "type": "Cyber & SSI",
         "desc": "Compromission infrastructure critique"},
    ]

    all_scenarios = (commercial_scenarios + financial_scenarios +
                     technical_scenarios + cyber_scenarios)

    for scenario in all_scenarios:
        score = scenario["G"] * scenario["F"] * scenario["P"]
        scenario["score"] = score
        scenario["classification"] = classify_from_score(score)
        scenario["sector"] = random.choice(SECTORS)
        scenarios.append(scenario)

    # Multiplier les sc√©narios pour plus de poids
    multiplied = []
    for scenario in scenarios:
        for _ in range(50):  # Chaque sc√©nario r√©el compte comme 50 exemples
            variant = scenario.copy()
            # L√©g√®res variations
            variant["G"] = max(1, min(5, variant["G"] + random.choice([-1, 0, 0, 0, 1])))
            variant["F"] = max(1, min(5, variant["F"] + random.choice([-1, 0, 0, 0, 1])))
            variant["P"] = max(1, min(5, variant["P"] + random.choice([-1, 0, 0, 0, 1])))
            variant["score"] = variant["G"] * variant["F"] * variant["P"]
            variant["classification"] = classify_from_score(variant["score"])
            multiplied.append(variant)

    return pd.DataFrame(multiplied)


def train_model(df: pd.DataFrame, model_type: str = "random_forest"):
    """
    Entra√Æne le mod√®le de classification des risques.
    """
    print(f"\n{'='*60}")
    print(f"Entra√Ænement du mod√®le: {model_type}")
    print(f"{'='*60}")

    # Encodage des variables cat√©gorielles
    cat_encoder = LabelEncoder()
    type_encoder = LabelEncoder()
    class_encoder = LabelEncoder()

    df['category_encoded'] = cat_encoder.fit_transform(df['category'])
    df['type_encoded'] = type_encoder.fit_transform(df['type'])
    df['classification_encoded'] = class_encoder.fit_transform(df['classification'])

    # Features et target
    X = df[['G', 'F', 'P', 'category_encoded', 'type_encoded']].values
    y = df['classification_encoded'].values

    # Split train/test
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42, stratify=y
    )

    # S√©lection du mod√®le
    if model_type == "random_forest":
        model = RandomForestClassifier(
            n_estimators=200,
            max_depth=15,
            min_samples_split=5,
            min_samples_leaf=2,
            class_weight='balanced',
            random_state=42,
            n_jobs=-1
        )
    elif model_type == "gradient_boosting":
        model = GradientBoostingClassifier(
            n_estimators=150,
            max_depth=10,
            learning_rate=0.1,
            random_state=42
        )
    else:
        raise ValueError(f"Type de mod√®le non support√©: {model_type}")

    # Entra√Ænement
    print("\nEntra√Ænement en cours...")
    model.fit(X_train, y_train)

    # √âvaluation
    y_pred = model.predict(X_test)

    print("\nüìä Rapport de classification:")
    print(classification_report(y_test, y_pred,
                               target_names=class_encoder.classes_))

    print("\nüìà Matrice de confusion:")
    cm = confusion_matrix(y_test, y_pred)
    print(pd.DataFrame(cm,
                      index=class_encoder.classes_,
                      columns=class_encoder.classes_))

    # Cross-validation
    cv_scores = cross_val_score(model, X, y, cv=5)
    print(f"\nüéØ Score de validation crois√©e: {cv_scores.mean():.4f} (+/- {cv_scores.std() * 2:.4f})")

    # Importance des features
    if hasattr(model, 'feature_importances_'):
        print("\nüîç Importance des features:")
        features = ['G', 'F', 'P', 'category', 'type']
        for feat, imp in zip(features, model.feature_importances_):
            print(f"  {feat}: {imp:.4f}")

    return model, cat_encoder, type_encoder, class_encoder


def save_model(model, cat_encoder, type_encoder, class_encoder,
               output_dir: str = None):
    """
    Sauvegarde le mod√®le et les encodeurs.
    """
    if output_dir is None:
        output_dir = OUTPUT_DIR

    # Sauvegarder le mod√®le
    model_path = os.path.join(output_dir, 'risk_classifier.pkl')
    joblib.dump(model, model_path)
    print(f"\n‚úÖ Mod√®le sauvegard√©: {model_path}")

    # Sauvegarder les encodeurs
    encoders = {
        'category': cat_encoder,
        'type': type_encoder
    }
    encoders_path = os.path.join(output_dir, 'encoders.pkl')
    joblib.dump(encoders, encoders_path)
    print(f"‚úÖ Encodeurs sauvegard√©s: {encoders_path}")

    # Sauvegarder l'encodeur de classification
    class_encoder_path = os.path.join(output_dir, 'classification_encoder.pkl')
    joblib.dump(class_encoder, class_encoder_path)
    print(f"‚úÖ Encodeur de classification sauvegard√©: {class_encoder_path}")


def save_training_data(df: pd.DataFrame, filename: str = "training_data.csv"):
    """
    Sauvegarde les donn√©es d'entra√Ænement pour r√©f√©rence.
    """
    os.makedirs(DATA_DIR, exist_ok=True)
    filepath = os.path.join(DATA_DIR, filename)
    df.to_csv(filepath, index=False)
    print(f"‚úÖ Donn√©es d'entra√Ænement sauvegard√©es: {filepath}")


def main():
    """
    Point d'entr√©e principal pour l'entra√Ænement du mod√®le.
    """
    print("üöÄ SafeQore - Entra√Ænement du mod√®le ML")
    print(f"üìÖ Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")

    # G√©n√©ration des donn√©es
    print("\nüì¶ G√©n√©ration des donn√©es synth√©tiques...")
    synthetic_data = generate_synthetic_training_data(n_samples=5000)
    print(f"  - Donn√©es synth√©tiques: {len(synthetic_data)} √©chantillons")

    print("\nüì¶ G√©n√©ration des sc√©narios r√©alistes...")
    realistic_data = generate_realistic_scenarios()
    print(f"  - Sc√©narios r√©alistes: {len(realistic_data)} √©chantillons")

    # Combiner les donn√©es
    full_data = pd.concat([synthetic_data, realistic_data], ignore_index=True)
    print(f"\nüìä Total des donn√©es d'entra√Ænement: {len(full_data)} √©chantillons")

    # Distribution des classes
    print("\nüìà Distribution des classes:")
    print(full_data['classification'].value_counts())

    # Sauvegarder les donn√©es d'entra√Ænement
    save_training_data(full_data)

    # Entra√Æner le mod√®le
    model, cat_enc, type_enc, class_enc = train_model(
        full_data,
        model_type="random_forest"
    )

    # Sauvegarder le mod√®le
    save_model(model, cat_enc, type_enc, class_enc)

    print("\n‚ú® Entra√Ænement termin√© avec succ√®s!")


if __name__ == "__main__":
    main()
